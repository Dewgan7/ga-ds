{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "## What is Pandas?\n",
    "\n",
    "Pandas is a python library providing rich functionality on top of numpy. In addition to 'Excel like' tables, Pandas works well with numpy constructs and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "Pandas series are like 1-dimensional numpy arrays, except that they are _labeled_, or have indices. In addition, the elements can be numeric, bools, strings, date time objects, functional objects, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_series = pd.Series( np.random.random(10) )\n",
    "int_series.head()\n",
    "int_series.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_series = pd.Series( np.random.random(10) )\n",
    "num_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_series = pd.Series([x for x in 'abcdefg'])\n",
    "str_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tup_series = pd.Series([(x,1) for x in range(10)])\n",
    "tup_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_series = pd.Series( [map for x in range(5) ])\n",
    "fun_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes\n",
    "(These are not the same as the _labels_ mentioned in supervised learning\n",
    "Each row of the pandas series has an index by default. In fact, you can specify your own indices perform fast lookups, grouping operations, descriptive stats associated with these indices.\n",
    "\n",
    "Indices can be strings, integers, or even time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries1 = pd.Series(np.random.random(5), index = ['CA','AK','IL','IN','NY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indSeries2 = pd.Series(np.random.random(3), index=['CA','IL','WA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indSeries1 + indSeries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries = pd.Series(np.random.random(5), index= pd.date_range('2015-01-01','2015-06-01',freq='m'))\n",
    "datSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datSeries.resample('q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "DataFrames are extensions of series into tables. They can have multiple indices (rows) and columns. Think of data frames as horizontally stacked series sharing the same set of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random((5,5)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_idx = pd.date_range('2015-01-01','2015-01-05',freq='d')\n",
    "df_col = ['sun','mon','tues','wed','thurs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random((5,5)),index=df_idx,columns=df_col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean()\n",
    "df.min()\n",
    "df.cumsum()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns #List the column labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index # List the rows labels of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sun # the columns can be addressed directly as pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sun'] # this way is more preferable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ ['sun'] ] # Index by label vs. array returns different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[ ['sun','mon'] ] # Can just select certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix['2015-01-01'] # rows can be addressed through ix, also returns a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[0] # same as above. ix supports both label and index based lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['fri'] = 1.0* df['wed'] + 2.0 * df['thurs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful here. axis is switched with pandas. Here, axis=0 refers to rows, axis=1 refers to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('fri',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('2015-01-01',axis=0) #wont work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop( pd.Timestamp('2015-01-01'), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[ pd.Timestamp('2015-01-01') ] = pd.Series(np.random.random(6),index=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create dataframes using a dictionary of objects for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'a': 1.,\n",
    "                    'b': pd.Timestamp('2015-01-01'),\n",
    "                    'c': pd.Series(np.random.random(),index=list(range(10))),\n",
    "                    'd': 'foo'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting  dataframes\n",
    "\n",
    "Subsetting dataframes works similarly to numpy, but with some additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ df['sun'] > .5 ] #Subset certain rows, where the 'sun' column for that row is greater than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[ (df['sun'] > .5) & (df['mon'] < .6) ] #multiple conditions, use tuples for each condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Subsetting\n",
    "\n",
    "We've subsetted portions of the columns and rows. What if we need to select from both the columns and rows?\n",
    "\n",
    "#### Indexing functions summary\n",
    "\n",
    "Pandas Dataframes support various methods for indexing:\n",
    "\n",
    "- .iloc <- Index by integer/position\n",
    "- .loc  <- Index by labels\n",
    "- .ix   <- Supports both label and integer/positional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[1:3,0:2] #Integer indexing into the rows and columns using noninclusive endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['2015-01-02':'2015-01-03',['sun','mon'] ] #NOTE the date range slice is INCLUSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[ '2015-01-01':'2015-01-03',0:2 ] #Mix of positional and label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(5))\n",
    "type(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df3.ix[:,0]) #Note that the Type changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df3.ix[:,0:1]) #Still a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple indexing\n",
    "Pandas allows you to have more than one set of indices or columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(30,5),index=pd.date_range('2015-1-1','2017-7-1',freq='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['blah'] = ['b1','b2','b3']*10\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.reset_index() #Reset the index of df3, set it as a new column\n",
    "df3 = df3.set_index(['blah','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.index.names = ['blah','date']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc['b1'] #Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[ [pd.Timestamp('2015-01-31')]  ] #doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[('b1','2015-01-31')] # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can address up until the left most unaddressed level\n",
    "df4 = pd.DataFrame(np.random.randn(8),index=['idx'+str(x) for x in range(8)])\n",
    "df4['idx2'] = ['foo','foo','bar','bar']*2\n",
    "df4['idx3'] = ['fah','bah']*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4.reset_index().set_index(['index','idx2','idx3'])\n",
    "df4.index.names = ['idx1','idx2','idx3']\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Group By: Split-Apply-Combine\n",
    "Pandas provides for powerful aggregation within 'groups'. The process involves:\n",
    "* **Splitting** the data into groups based on criteria\n",
    "* **Applying** a function to each of the groups independently\n",
    "* **Combining** the groups back together into a dataframe\n",
    "\n",
    "The **Apply** step can be any function such as Aggregating values (mean,min,median,count,etc), Transforming values (similar to the winsorization example), or Filtration (removing data)\n",
    "\n",
    "The most similar paradigm would be SQL based statements such as:\n",
    "```\n",
    "SELECT column1, mean(column2), max(column3)\n",
    "FROM TheTable\n",
    "GROUP BY column1, column2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['foo','bar','foo','bar',\n",
    "                         'foo','bar','foo','foo'],\n",
    "                   'B': ['one','one','two','three',\n",
    "                         'two','two','one','three'],\n",
    "                   'C': np.random.randint(0,10,8),\n",
    "                   'D': np.random.randint(0,10,8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('A') #groupby object\n",
    "grouped = df.groupby(['A','B']) #creates groups based on distinct combn of A and B\n",
    "#Groupby does NOT split. It just validates a correct mapping of labels to group names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, group in grouped:\n",
    "    print \"Name:\", name\n",
    "    print \"Group:\", group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can also split on columns, and even based on your own rules\n",
    "def tmp(letter):\n",
    "    if letter.lower() in 'aeiou':\n",
    "        return 'vowel'\n",
    "    else:\n",
    "        return 'consonant'\n",
    "\n",
    "\n",
    "grouped = df.groupby(tmp, axis=1)\n",
    "grouped.get_group('consonant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Various descriptive stats measured on each of the groups\n",
    "grouped.all() # All of the elements are true (or coercible to true)\n",
    "grouped.any()\n",
    "grouped.count()\n",
    "grouped.sum()\n",
    "grouped.groups #Returns a dict of the groups. Keys are the group titles, values are axis labels\n",
    "#Grouped itself is an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(np.random.randn(8),index=['idx'+str(x) for x in range(8)],columns=['val'])\n",
    "df4['idx2'] = ['foo','foo','bar','bar']*2\n",
    "df4['idx3'] = ['fah','bah']*4\n",
    "df4 = df4.reset_index().set_index(['index','idx2','idx3'])\n",
    "df4.index.names = ['idx1','idx2','idx3']\n",
    "\n",
    "#Once you have groupings, you can perform functions on them\n",
    "grouped = df4.groupby(level=2) # Groupby using the 3rd index\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OR you can specify your own aggregation functions\n",
    "grouped.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can handle multiple aggregations on the columns through dicts\n",
    "grouped.agg({'val': ['mean','min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#you can also do in place transformations of the data\n",
    "def zScore(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "grouped = df4.groupby(level=2)\n",
    "grouped.transform(zScore) \n",
    "#Group by 'fah' and 'bah', take all of the elements in them and zscore\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply is similar to transform, \n",
    "grouped.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Does not do what you think. Notice that each element got of 'fah' got the same mean\n",
    "grouped.transform(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Pandas also has the ability to dynamically download datasets using the read_csv function.\n",
    "\n",
    "Download the following dataset using the following command. Note that this may take a while--you'll know if Python is still running if there is an asterisk to the left of the command\n",
    "```\n",
    "import pandas as pd\n",
    "chi = pd.read_csv('https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv?accessType=DOWNLOAD')\n",
    "chi.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is the shape of this data set? How many rows and columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many distinct cities are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common Inspection Type? Hint: Use `groupby` and `idxmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
